### 1. INTRODUCTION

---

- THREE key capabilities:
  - publish and subscribe to streams of records, similar to a mq
  - store streams of records in a fault-tolerant durable(容错持久的) way
  - process streams of records as they occur.

- using it to build:
  - real-time streaming data pipelines that reliably get data between systems or applications
  - real-time streaming applications that transform or react to the streams of data.

- a few concepts:
  - run as a cluster on servers that can span multiple datacenters.
  - stores streams of records in categories called topics.
  - each record consists of (1)a key, (2)a value and (3)a timestamp.

- four core APIs:
  - Producer API
  - Consumer API
  - Streams API
  - Connector API

- Partitioned log: the Kafka cluster maintains a partitioned log
  - EACH partition is an ordered, immutable sequence of records
  - offset: the records in the partitions are each assigned a sequential ID(offset)

- Kafka's performance is effectively constant
  - storing data for a long time is not a problem.

- PERSIST: (logs/consumer perspective)
  - (logs)persist all published records:
    - The Kafka cluster durably persists all published records-whether or not they have been consumed-using a configurable retention period.
  - (consumer)The ONLY metadata retained on a per-consumer basis:
    - is the OFFSET of that consumer in the log. Controlled by the consumer
      - (1) a consumer can reset to an older offset
      - (2) OR skip to the most recent record

- total order (within a partition):
  - Kafka only provides a total order over records within a partition. 
  - NOT between diff partitions in a topic.

- if you require a total order (within a topic):
  - only one partition -> only one consumer process per consumer group

- messaging:
  - (traditionally)two models: queuing & publish-subscribe
    - queuing: (strength+) divide up the processing of data over multiple consumer instances - scale processing
    - publish-subscribe: allows you broadcast data to multiple processes - multiple processes
  - (Kafka) it allows you to broad messages to multiple consumer group.
    - consumer group concept: it generalizes these two (queuing&publish-subscribe) concepts.
    - as with a queue, group can divide up processing over the members(of the consumer group)
    - as with publish-subscribe, it broadcast messages to multiple consumer groups.

- Advantage of Kafka:
  - every topic can scale processing and is also multi-subscriber. -no need to choose one or the other

- Kafka can provide BOTH ordering guarantees & load balancing over a pool of consumer processes.
  - EACH partition is consumed by exactly one consumer in the group
  - NOTE: there CANNOT be more consumer instances in a consumer group  than partitions

- Kafka is a very good storage system.(it allows producers to wait ack)
  - Data is wirtten to disk
  - replicated for fault-tolerance

- Kafka is a special distributed filesystem dedicated to high-performance, low-latency commit log storage, replication, and propagation.
  - it takes storage seriously and allows clients to control their read position.

- Stream Processing:
  - a stream processor is anything that takes continual streams of data from input topics, performs some processing on this input, and produces continual streams of data to output topics
  - to (1) compute aggregations off OR (2) join streams together. 
  - e.g.: handling out-of-order data, reprocessing input as code changes, performing stateful computations, etc.
  - Streams API builds on the core primitives Kafka.
 
  
- Kafka plays a role as streaming platform - combination of messaging, storage, and stream processing. 
  - (streaming applications)it allows storing and processing historical data from the past, like HDFS.
  - (streaming data pipelines)it allows processing future messages that will arrive after you subscribe.
 
---

##### 1.2. Use Cases

- cases:
  - Messaging(good solution for large scale msg processing applications): works as a replacement for a traditional message broker
    - To decouple processing from data producers(traditional msg broker)
    - To buffer unprocessed messages(traditional msg broker)
    - better throughput
    - built-in partition
    - repication
    - fault-tolerance
  - website activity tracking: a set of real-time publish-subscribe feeds.
    - page views, searches, etc.
    - one topic per activity type.
  - metrics: aggregating statistics from distributed applications to produce centralized feeds of operational data.
  - log aggregation: a log aggregation solution.
    - to collect physical log files off servers and put them in a central place.
    - compared with log-centric sys Scribe or Flume
      - to provide equally good performances, stronger durability guarantees and lower end-to-end latency
  - stream processing: process data in pipelines consisting of multiple stages.
    - consume raw input data
    - aggregated, enriched or transformed into new topics
      - e.g.: crawl article -> publish to a topic -> normalize/deduplicate content -> publish cleansed article to a new topic -> recommend
      - as of 0.10.0.0, the light-weight library Kafka Streamscan perform such data processing.
  - event sourcing: state changes are logged as a time-ordered sequence of records
  - commit log: similar to Apache BookKeeper
    - external commit-log for a distributed system.

---

##### 1.3 Quick Start

- 1.download: 

  ```  
  tar -xzf kafka_2.11-1.1.0.tgz
  cd kafka_2.11-1.1.0
  ```
- 2.start the server:

  ```
  # quick-and-dirty single-node ZooKeeper instance
  bin/zookeeper-server-start.sh config/zookeeper.properties
  ```

- 3.create a topic:
 
  ```
  bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
  bin/kafka-topics.sh --list --zookeeper localhost:2181
  ```

- 4.send msg:
  
  ```
  bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
  This is a message
  This is another message
  ```

- 5.start a consumer:
  
  ```
  bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

  ```
- 6.Setting up a multi-broker cluster

  ```
  cp config/server.properties config/server-1.properties
  cp config/server.properties config/server-2.properties

  # config/server-1.properties:
  #   broker.id=1
  #   listeners=PLAINTEXT://:9093
  #   log.dir=/tmp/kafka-logs-1
 
  # config/server-2.properties:
  #   broker.id=2
  #   listeners=PLAINTEXT://:9094
  #   log.dir=/tmp/kafka-logs-2

  bin/kafka-server-start.sh config/server-1.properties &
  bin/kafka-server-start.sh config/server-2.properties &

  #create a topic with a replication factor of three
  bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
  #check topic status:
  bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
  #test
  bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic
  bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topic
  #test out fault-tolerance
  ps aux | grep server-1.properties
  kill -9 <PID>
  bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
  ```

- Use Kafka Connect to import/export data:
  
  ```
  echo -e "foo\nbar" > test.txt
  bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties
  more test.sink.txt
  bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning
  #{"schema":{"type":"string","optional":false},"payload":"foo"}
  #{"schema":{"type":"string","optional":false},"payload":"bar"}

  ```

- 8.Use Kafka Streams to process data:
  - Kafka Streams is a client library for building mission-critical real-time applications and microservices

---

### 2. APIs

- 4 APIs:
  - Producer API: allows applications to send streams of data to topics
  - Consumer API: allows to read streams of data from topics 
  - Streams API: allows transforming streams of data from input topics to output topics
  - Connect API: alows implementing connectors -> continually pulll from from source sys/app into kafka OR push from Kafka to sink sys/app
  - AdminClient API: allows managing/inspecting topics, brokers, and other Kafka objects.

  ```
  # enable producer/consumer/AdminClient API:
  <dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>1.1.0</version>
  </dependency>

  # streams API:
  <dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-streams</artifactId>
    <version>1.1.0</version>
  </dependency>
  ```
---

### 3. Configuration

- The essential configurations:
  - broker.id 
  - log.dirs 
  - zookeeper.connect
 
---

### 4. Design

- Motivation: create a unified platform for handling all the real-time data feeds (for large companies)
  - high-throughput to support high volume event streams¸ like rt log aggregation.
  - deal with large data backlogs to support periodic data loads from offline systems.
  - handle low-latency delivery
  - support partitioned, distributed, rt processing of these feeds to create new feeds.
  - guarantee fault-tolerance

- Persistence: -Don't fear the filesystem - Kafka relies heavily on the filesytem for storing and caching messages.
  - disks are both much slower and much faster than people expect
  - a properly designed disk structure can often be as fast as the network
  - the performance of linear writes on a JBOD configuration with six 7200rpm SATA RAID-5 array is about 600MB/sec
  - BUT the random writes is only about 100k/sec
  - linear reads and writes 
    - they are the most predictable of all usage patterns
    - they are heavily optimized by the operating system

- read-ahead and write-behind: 
  - A modern operating system provides read-ahead and write-behind techniques 
  - TO prefetch data in large block multiples and group smaller logical writes into large physical writes

-  (twice)increasingly aggressive in the use of main memory ( disk caching with little performance penalty )
  - two copies: a process maintains an in-process cache of the data, this data will likely be duplicated in OS pagecache  
  - effectively storing everything twice

- NO JVM: using filesystem & pagecache is superior to JVM solution.
  - 1.The memory overhead of objects is very high, often doubling the size of the data stored (or worse).
  - 2.Java garbage collection becomes increasingly fiddly and slow as the in-heap data increases.

- cold cache & warm cache:
  - in-process cache need to be rebuilt in mem 
  - pagecache-centric design will be better

- Constant Time Suffices:
  - The persistent data structure is often a per-consumer queue (with BTree OR other general-purpose random access data structures)
  - (-)Btree operations are O(log N), it is considered equivalent to constant time. BUT
    - Disk seeks come at 10 ms a pop. a handful of disk seeks leads to very high overhead.
  - (+) logging solution: 
    - decoupled from the data size VS. poor seek performance (1/3 the price and 3x the capacity) 
      - Compared with old msging system, having access to unlimited disk space without performance penalty can bring new features, like retain messages for relatively long period
    - persistent queue is built on simple reads and appends to files 
      - the advantage: all operations are O(1) 
      - reads do not block writes or each other

- Efficiency
  - TWO common causes of inefficiency: too many small I/O operations & excessive byte copying.
    - I/0 example: downstream infrastructure service can easily become a bottleneck due to a small bump in usage 
    - copying example: (4 copies + 2 sys call)the common data path for transfer of data from file to socket
      - 1.The operating system reads data from the disk into pagecache in kernel space
      - 2.The application reads the data from kernel space into a user-space buffer
      - 3.The application writes the data back into kernel space into a socket buffer
      - 4.The operating system copies the data from the socket buffer to the NIC buffer(网卡缓冲区) where it is sent over the network

- solutions: (1) Batching + (2)standardized binary format + (3)sendfile & pagecache  ==(result in)==> no/less read activity on the consumers' disk
  - (I/O problems)Batching:"message set" turn a bursty stream of random message writes into linear writes that flow to the consumers. 
    -group msg & amortize the overhead of network roundtrip. -> (server)append a chunks of messages to its log in one go. (consumer) fetches large linear chunks at a time.
  - (byte copying)standardized binary message: shared by the producer, the broker, and the consumer
    - data chunks can be transferred without modification between them
  - (for network) sendfile system call: network transfer of persistent log chunks
    - based on unified binary msg format; provided by OS; transfer data out of pagecache to a socket
    - the only final copy to the NIC buffer is needed
    - This allows messages to be consumed at a rate that approaches the limit of the network connection. 
  - (bandwidth) Batch Compression: Kafka supports GZIP, Snappy, & LZ4 protocol; decompressed by the consumer.

- The producer features:
  - load balancing: (answer metadata requests) + (locality-sensitive processing in consumers)
    - ALLOW the user to specify a key/hash to partition -> ALLOW consumers to make locality assumptions about their consumption. 
      - chosen key(user id) then all data for a given user would be sent to the same partition
    - send data directly to the leader broker without any interventing routing tier.
      - which requires all kafka nodes can answer metadata request which servers are alive & where the leaders for the partitions of a topic are
  - Asyn send: 
    - accumulate data in mem & send out larger batches in a single request.
    - it can be configured (1) no more than a fixed number OR (2) wait no longer than some fixed latency bound(say 64k or 10ms)
    - accumulation of more bytes & few larger I/O operations

- The consumer features:
  - the consumer can issue "fetch" request to the broker, specifies its offset & rewind it to re-consume data
  - PUSH vs. PULL
    - Push: 
      - (-) the consumer tends to be overwhelmed when its rate of consumption falls bebind and catches up when it can (mitigate with backoff protocol)
      - (+) the consumer is able to consume at the maximum possible rate
    - PULL:
      - (+) get optimal batching without introducing unnecessary latency
      - (-) busy-waiting for data to arrive. if the broker has no data, the consumer may end up polling in a tight loop (solution: block in a "long poll" waiting ) 

- Consumer Position(Offset): keeping track of what has been consumed is
  - Normally way: 
    - (1) add ack feature to broker -> mark msg as "sent" or "consumed"
    - new problems created by (1): 
      - msg may be consumed twice if the msg is processed by consumer BUT fail to send ack.
      - performance: brokers must keep multiple states about every single msg
      - never acked: what to do with msg what are sent but never acked
  - Kafka solution:
    - topic is divided into a set of totally ordered partitions, each of which is consumed by exactly one consumer within each subscribing consumer group at a given time.
    - the position of a consumer in each partition is just a single integer. the number == msg ack & it is very cheap.
    - side benefit: consumers can deliberately rewind back to an old offset and re-consume data.

- Message Delivery Semantics: (note: Kafka supports exactly-once delivery in Kafka Streams)
  - Three possible message delivery guarantees:
    - At most once - Message may be lost but are never redelivered.
    - At least once - Message are never lost but may be redelivered. (by default)
    - Exactly once - each message is delivered once and only once.
  - Three possible strategy can be seemed as two problems
    - the durability guarantees for publishing a message
    - the guarantees when consuming a message
  - Kafka has notions: committed message, alive partition
  - problems:
    - if a producer attempts to publish a message and experiences a network error it cannot be sure if this error happened before or after the message was committed.
  - as of 0.11.0.0 (producer) 
    - Prior to 0.11.0.0, if a producer failed to receive a response indicating that a message was committed, it had little choice but to resend the message. 
    - (1)Kafka supports an idempotent delivery option which guarantees that resending will not result in duplicate entries in the log.
      - 1) assign each producer an ID
      - 2) deduplicate messages using a sequence number that is sent by the producer along with every message.
    - (2) Kafka supports the ability to send message to multiple topic partitions using transaction-like semantics.
      - all succeed or fail
  - async OR wait(producer):
    - The producer can specify that it wants to perform the send completely asynchronously or that it wants to wait only until the leader have the message
  - describe message delivery semanitics from the poit-of-view of the consumer:
    - (Ideally) all replicas have the same log with same offsets. The consumer controls its position.
    - (Problem) if the consumer never crashed it could store position in mem. if crashed, this partition should be taken over by new proc, the proc need choose position. How?
    - (Solutions) Three ways:
      - [at-most-once] consumer reads msg -> save offset in log -> process msg
        - (consumer failure) there is a possibility that the consumer process crashes after saving BUT before output
	    - (workaround -> at-most-once) the other process will take over processing & start at the saved position. ignore a few msg that had not been processed
      - [at-least-once] consumer reads msg -> process msg -> save offset in log
        - (consumer failure) there is a possibility that the consumer process crashes after processing msg BUT before saving position
	    - (workaround -> at-least-once) the new consumer will take over the first few msg that had been processed.
      - [exactly once] consuming from a Kafka and producing to another topic (Kafka Streams application)
        - (1) transactional producer capabilities(0.11.0.0)-> store consumer's position as a message in a topic (in one transaction) -> push/commit original msg and offset msg together
        - (2) read uncommitted VS. read committed: read from output stream topic. 
  - Limitation: writing to external system:
    - [problem]coordinate the consumer's position with what is actually stored as output
    - [old solution] two-phase commit between the storage of the consumer position and the storage of the consumers output.
    - [simple/general solution] store its offset and in the same place as its output (because some output sys may not support two-phase commit)
      - e.g. consider a Kafka Connect connector which populates data in HDFS along with the offsets of the data it reads  
      - either data and offsets are both updated or neither is

- Replication
  - kafka is meant to be used with replication by default (implement un-replicated topics as replicated topics with replication factor is 1)
  - the unit of replication is the topic partition
  - each partition has 1 leader and 0+ follwers
  - all reads and writes go to the leader of the partition.
  - followers are identical to the leader's log 
  - of cause, leader may have a few as-yet unreplicated messages at the end of its log.
  - what it means for a node to be "alive" - "in sync"
    - (1) a node must be able to maintain its session with ZooKeeper(heartbeat mechanism)
    - (2) if it is a slave it must replicate the writes happening on the leader and not fall "too far" behind.
    - configuration "replica.lag.time.max.ms" determine if a follower (dies, get stuck, falls bebind) should be removed by the leader
  - Kafka handle "fail/recover" model of failures BUT does not handle so-called "Byzantine" failures (perhaps due to bugs or foul play)
  - committed messages:
    - committed message will not be lost, as long as there is at least one in sync replica alive
    - Only committed messages are ever given out to the consumer. 
      - (consumer side) consumer need not worry about a msg what could be lost if the leader fails.
      - (producer side) producer has the option of either waiting for msg to be committed or not. (tradeoff between durability and latency)
    - topic setting "minimum number" of in-sync replicas (can be as low as just the leader)
      - a less stringent acknowledgement is requested by the producer,  then the message can still be committed, and consumed
