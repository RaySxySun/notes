# Setup a kafka playground
> http://wurstmeister.github.io/kafka-docker/
> https://github.com/wurstmeister/kafka-docker

#================================= run tomcat docker
$ docker run -it --rm -p 8888:8080 hub.ecf-poc.com:9999/micro-service/fms-bff

#================================= busybox test
$ docker run -it  hub.ecf-poc.com:9999/library/busybox:latest ping trip-traffic-es-1

alias busybox="docker run -it --rm  busybox"

#================================= connectivity test
$ nc -vz -w 10 192.168.2.72 9200

#================================= docker-compose up doesn't pull down latest image if the image exists locally
$ docker-compose pull && docker-compose up

#================================= build docker images with specified network
$ docker run -it --network docker01 hub.ecf-poc.com:9999/library/fms-base:latest bash

#================================= merge files and filter out duplicate info (in Dockerfile)
COPY ./hosts /tmp/hosts
COPY ./fms-bff-latest/conf /opt/ecf/web_component/fms-bff-latest/conf
RUN cat /tmp/hosts /etc/hosts | sort -u > /etc/hosts

#================================= input & redirect
$ cat <<EOF > /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

#================================= k8s

kubectl create -f target/services/kube-dns.yaml
kubectl -n kube-system get svc

#================================= AWK
  # clean all invalid images
  docker rmi -f $(docker images | grep non | awk '{print $3}')
  # print 2nd & last column with space padding
  docker ps | grep fms | awk '{printf("%-40s %5s\n",$NF,$2)}'
  ```
  fms-report-engine                        hub.ecf-poc.com:9999/micro-service/fms-report-engine:latest
  fms-biz-rule-mgmt                        hub.ecf-poc.com:9999/micro-service/fms-biz-rule-mgmt:latest
  fms-org-mgmt                             hub.ecf-poc.com:9999/micro-service/fms-org-mgmt:latest
  fms-event-notification                   hub.ecf-poc.com:9999/micro-service/fms-event-notification:latest
  ```

#================================= Print curl pretty format
$ curl -XGET http://awesome.com/api/v1/data | python -m json.tool

#================================= kube-proxy
# ISSUE: error looking for path of conntrack: exec: "conntrack": executable file not found in $PATH
yum install conntrack-tools

#================================= check docker container
sudo docker inspect --format '{{ .State.Pid }}' reactor-worker


#================================= three-way&four-way handshake > establish connection
Client ------SYN-----> Server
Client <---ACK/SYN---- Server ----①
Client ------ACK-----> Server

> terminate connection
Client ------FIN-----> Server
Client <-----ACK------ Server ----②
Client <-----FIN------ Server ----③ (at this moment the client has been in FIN_WAIT_2 state)
Client ------ACK-----> Server

#================================= redis
# check all keys
> KEYS *


#================================= REACTOR

http://{{service_host}}:{{service_port}}/service/api/resourceBundle-management/v1/resourceBundle/deploy
ResourceBundleServiceRestful.deploy -> ResourceBundleServiceImpl.deploy (conent -> ApplicationArchive -> ResourceBundle -> save/update)
# READ file from postgres bytea field
$ psql -h 192.168.2.50 -p 5432 -U reactor -d reactor        #access postgres db
$ \d+ resourcebundle                                        #check table description

                              Table "public.resourcebundle"
   Column  |          Type          | Modifiers | Storage  | Stats target | Description 
  ---------+------------------------+-----------+----------+--------------+-------------
   id      | bigint                 | not null  | plain    |              | 
   content | oid                    | not null  | plain    |              | 
   name    | character varying(255) | not null  | extended |              | 
   version | character varying(255) | not null  | extended |              | 

$ select  * from resourcebundle;

  Id  Content Name                              Version
  ----------------------------------------------------------
  10  24578   reactor:resource-bundle:default   1
  40  16599   rms-resources-v2                  1.0-SNAPSHOT
  41  16600   ResourceBundle-Example            1.0-SNAPSHOT

  # -- read bytea 
  # -- $ \copy (SELECT encode(content, 'hex') FROM resourcebundle where name='ResourceBundle-Example') TO '/tmp/content.hex'
  # -- $ xxd -p -r content.hex > content.jpg
  # -- instead of reading file from bytea, the blob file should read directly with lo_get()

$ \copy (SELECT lo_get(content) FROM resourcebundle where name='reactor-app-ResourceBundle-1') TO '/tmp/content.hex';
$ xxd -p -r content.hex > content.jar

  # -- read bytea 
  # -- $ \copy (SELECT encode(content, 'hex') FROM resourcebundle where name='ResourceBundle-Example') TO '/tmp/content.hex'
  # -- $ xxd -p -r content.hex > content.jpg
  # -- instead of reading file from bytea, the blob file should read directly with lo_get()

  # -- 
  >> I know this is none of the user's business, but I'm wondering how
  >> blob's implemented as oid are stored in the postgresql data storage.
  >> Are each of them kept in a separate file, or are they chunked into
  >> pieces and scattered ?
  >
  > They're in chunks in the pg_largeobject catalog.
  > https://www.postgresql.org/docs/devel/catalog-pg-largeobject.html

